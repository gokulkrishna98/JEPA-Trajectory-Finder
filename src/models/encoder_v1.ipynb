{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm0-VNk8zODs",
        "outputId": "022d3aed-2176-4ba3-e283-45406b673a4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightly in /usr/local/lib/python3.10/dist-packages (1.5.15)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly) (2024.8.30)\n",
            "Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.3.2)\n",
            "Requirement already satisfied: lightly_utils~=0.0.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (0.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.26.4)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lightly) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly) (0.20.1+cu121)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.9.2)\n",
            "Requirement already satisfied: pytorch_lightning>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.4.0)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly) (2.2.3)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from lightly) (3.1.15)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly_utils~=0.0.0->lightly) (11.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning>=1.0.4->lightly) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning>=1.0.4->lightly) (1.6.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning>=1.0.4->lightly) (0.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly) (3.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->lightly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lightly) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (4.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install lightly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFPE8o-xzyX6",
        "outputId": "8ab756ab-abf1-442f-efa0-3222311c13db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjfI6cPFz1t-",
        "outputId": "0dbcc4c7-6a13-4d54-9e7a-98c511997895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['dataset', '__pycache__', 'dataset.py', 'dataset2']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = \"DL\"\n",
        "\n",
        "GOOGLE_DRIVE_PATH = os.path.join(\"drive\", \"My Drive\", GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))\n",
        "\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R69t_AzAzODt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as tr\n",
        "\n",
        "from dataset import TrajectoryDataset\n",
        "\n",
        "from lightly.models.modules.heads import VICRegProjectionHead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzvyG-k2zODt",
        "outputId": "068a50a0-918c-4b1d-d81b-264744286cbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data_points 79\n",
            "Shape of state: torch.Size([64, 17, 2, 65, 65])\n",
            "Shape of action: torch.Size([64, 16, 2])\n"
          ]
        }
      ],
      "source": [
        "dataset = TrajectoryDataset(\n",
        "    data_dir = \"/content/drive/My Drive/DL/dataset2\",\n",
        "    states_filename = \"states_5000.npy\",\n",
        "    actions_filename = \"actions_5000.npy\",\n",
        "    s_transform = None,\n",
        "    a_transform = None,\n",
        ")\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "first_datapoint = next(iter(dataloader))\n",
        "state, action = first_datapoint\n",
        "\n",
        "print(f\"Number of data_points {len(dataloader)}\")\n",
        "print(f\"Shape of state: {state.shape}\")\n",
        "print(f\"Shape of action: {action.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jIdwdk5nzODu"
      },
      "outputs": [],
      "source": [
        "class VICReg(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = VICRegProjectionHead(\n",
        "            input_dim=512,\n",
        "            hidden_dim=1024,\n",
        "            output_dim=1024,\n",
        "            num_layers=3,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x).flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6sHm_AF-zODu"
      },
      "outputs": [],
      "source": [
        "resnet = torchvision.models.resnet18()\n",
        "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
        "model = VICReg(backbone)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum= 0.9, weight_decay=1.5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGrhJ1nPzODu",
        "outputId": "64ea9206-346d-44f7-dd5b-a6840df6fd40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YW8Q8vl5zODv"
      },
      "outputs": [],
      "source": [
        "def get_byol_transforms(mean, std):\n",
        "    # Define the first augmentation pipeline\n",
        "    transformT = tr.Compose([\n",
        "        tr.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
        "        tr.RandomRotation(degrees=90),  # Random rotation\n",
        "        tr.GaussianBlur(kernel_size=(23, 23), sigma=(0.1, 2.0)),  # Gaussian blur\n",
        "        tr.Normalize(mean, std),  # Normalize for 2 channels\n",
        "    ])\n",
        "\n",
        "    # Define a slightly different second augmentation pipeline\n",
        "    transformT1 = tr.Compose([\n",
        "        tr.RandomVerticalFlip(p=0.5),  # Random vertical flip\n",
        "        tr.RandomRotation(degrees=45),  # Different random rotation\n",
        "        tr.GaussianBlur(kernel_size=(15, 15), sigma=(0.1, 1.5)),  # Gaussian blur with smaller kernel\n",
        "        tr.Normalize(mean, std),  # Normalize for 2 channels\n",
        "    ])\n",
        "\n",
        "    return transformT, transformT1\n",
        "\n",
        "\n",
        "def off_diagonal(matrix):\n",
        "    \"\"\"\n",
        "    Extracts the off-diagonal elements of a square matrix.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): A square matrix of shape (D, D).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: A tensor containing all off-diagonal elements.\n",
        "    \"\"\"\n",
        "    # Create a mask for off-diagonal elements\n",
        "    n = matrix.shape[0]\n",
        "    off_diag_mask = ~torch.eye(n, dtype=bool, device=matrix.device)\n",
        "\n",
        "    # Use the mask to extract off-diagonal elements\n",
        "    off_diag_elements = matrix[off_diag_mask]\n",
        "    # print(off_diag_elements)\n",
        "    return off_diag_elements\n",
        "\n",
        "\n",
        "def criterion(x, y, lmbd = 5e-3, invar = 25, mu = 25, nu = 1, epsilon = 1e-4):\n",
        "    bs = x.size(0)\n",
        "    emb = x.size(1)\n",
        "\n",
        "    std_x = torch.sqrt(x.var(dim=0) + epsilon)\n",
        "    std_y = torch.sqrt(y.var(dim=0) + epsilon)\n",
        "    var_loss = torch.mean(F.relu(1 - std_x)) + torch.mean(F.relu(1 - std_y))\n",
        "\n",
        "    invar_loss = F.mse_loss(x, y)\n",
        "\n",
        "    x = x - x.mean(dim=0)\n",
        "    y = y - y.mean(dim=0)\n",
        "    cov_z_a = (x.T @ x) / (bs - 1)\n",
        "    cov_z_b = (y.T @ y) / (bs - 1)\n",
        "    cov_loss = off_diagonal(cov_z_a).pow_(2).sum() / emb + off_diagonal(cov_z_b).pow_(2).sum() / emb\n",
        "\n",
        "    # print(f\"invar_loss: {invar_loss.item()}\")\n",
        "    # print(f\"var_loss: {var_loss.item()}\")\n",
        "    # print(f\"cov_loss: {cov_loss.item()}\")\n",
        "\n",
        "    loss = invar*invar_loss + mu*var_loss + nu*cov_loss\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yLMLhPUezODv"
      },
      "outputs": [],
      "source": [
        "def compute_mean_and_std():\n",
        "  num_channels = 2  # Assuming you have 2 channels\n",
        "  pixel_sum = [0] * num_channels\n",
        "  pixel_squared_sum = [0] * num_channels\n",
        "  total_pixels = 0\n",
        "\n",
        "  # Iterate through the dataset\n",
        "  for state, _ in dataloader:\n",
        "      # Iterate through each channel\n",
        "      for channel in range(num_channels):\n",
        "          channel_data = state[:, :, channel, :, :].reshape(-1)  # Flatten the current channel\n",
        "          pixel_sum[channel] += channel_data.sum().item()\n",
        "          pixel_squared_sum[channel] += (channel_data ** 2).sum().item()\n",
        "\n",
        "      # Total number of pixels per channel (all images combined)\n",
        "      total_pixels += state.size(0) * state.size(1) * state.size(3) * state.size(4)\n",
        "\n",
        "  # Calculate mean and std for each channel\n",
        "  mean = [pixel_sum[c] / total_pixels for c in range(num_channels)]\n",
        "  std = [\n",
        "      np.sqrt((pixel_squared_sum[c] / total_pixels) - (mean[c] ** 2))\n",
        "      for c in range(num_channels)\n",
        "  ]\n",
        "\n",
        "  print(f\"Mean per channel: {mean}\")\n",
        "  print(f\"Std per channel: {std}\")\n",
        "  mean.append(mean[1])\n",
        "  std.append(std[1])\n",
        "  return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A75Vu0FzODv",
        "outputId": "4810b68f-55f7-4321-aa92-078696ae92a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean per channel: [0.00023668267603448322, 0.009316061526496694]\n",
            "Std per channel: [0.003329996277483632, 0.028114841590122994]\n"
          ]
        }
      ],
      "source": [
        "mean, std = compute_mean_and_std()\n",
        "transformation1, transformation2  = get_byol_transforms(mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LRbL-AfzODw",
        "outputId": "e6e234c0-e135-4e4b-c361-4eb37153c1d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Training\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting Training\")\n",
        "def train(dataloader, epochs):\n",
        "  for epoch in range(epochs):\n",
        "      total_loss = 0\n",
        "      ind = 0\n",
        "      for batch in dataloader:\n",
        "          state, action = batch\n",
        "          img = state[:, 0, :, :, :]\n",
        "          img = torch.cat([img, img[:, 1:2, :, :]], dim=1)\n",
        "\n",
        "          x0 = transformation1(img)\n",
        "          x1 = transformation2(img)\n",
        "\n",
        "          x0 = x0.to(device)\n",
        "          x1 = x1.to(device)\n",
        "\n",
        "          z0 = model(x0)\n",
        "          z1 = model(x1)\n",
        "\n",
        "          loss = criterion(z0, z1)\n",
        "          total_loss += loss.detach()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          optimizer.zero_grad()\n",
        "          # print(f\"batch: {ind}\")\n",
        "          avg_loss = total_loss / len(dataloader)\n",
        "          ind = ind + 1\n",
        "      print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIo1bC7pzODw",
        "outputId": "43a7b358-04b0-4b94-aabf-38010206b2ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 00, loss: 37.53720\n",
            "epoch: 01, loss: 34.67337\n",
            "epoch: 02, loss: 33.28022\n",
            "epoch: 03, loss: 32.07617\n",
            "epoch: 04, loss: 31.24450\n",
            "epoch: 05, loss: 30.76028\n",
            "epoch: 06, loss: 30.49474\n",
            "epoch: 07, loss: 30.22291\n",
            "epoch: 08, loss: 29.99336\n",
            "epoch: 09, loss: 29.96262\n",
            "epoch: 10, loss: 29.49220\n",
            "epoch: 11, loss: 29.47420\n",
            "epoch: 12, loss: 29.21940\n",
            "epoch: 13, loss: 28.93957\n",
            "epoch: 14, loss: 28.87402\n",
            "epoch: 15, loss: 28.73059\n",
            "epoch: 16, loss: 28.52197\n",
            "epoch: 17, loss: 28.65028\n",
            "epoch: 18, loss: 28.29223\n",
            "epoch: 19, loss: 28.20359\n",
            "epoch: 20, loss: 28.36916\n",
            "epoch: 21, loss: 28.24691\n",
            "epoch: 22, loss: 28.01368\n",
            "epoch: 23, loss: 27.89042\n",
            "epoch: 24, loss: 27.83872\n",
            "epoch: 25, loss: 27.75111\n",
            "epoch: 26, loss: 27.69475\n",
            "epoch: 27, loss: 27.79646\n",
            "epoch: 28, loss: 27.54712\n",
            "epoch: 29, loss: 27.38757\n"
          ]
        }
      ],
      "source": [
        "train(dataloader, 30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
