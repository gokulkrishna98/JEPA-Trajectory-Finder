{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as tr\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import TrajectoryDataset\n",
    "from lightly.models.modules.heads import VICRegProjectionHead\n",
    "from encoder_train import save_model, compute_mean_and_std, get_byol_transforms, get_encoder_loss\n",
    "from encoder_train import criterion as VICReg_criterion\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting the Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data_points 62\n",
      "Shape of state: torch.Size([16, 17, 2, 65, 65])\n",
      "Shape of action: torch.Size([16, 16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokul/miniconda3/envs/ml/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:285: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)\n"
     ]
    }
   ],
   "source": [
    "dataset = TrajectoryDataset(\n",
    "    data_dir = \"../dataset/\",\n",
    "    states_filename = \"states.npy\",\n",
    "    actions_filename = \"actions.npy\",\n",
    "    s_transform = None,\n",
    "    a_transform = None,\n",
    "    length = 992    \n",
    ")\n",
    "\n",
    "# TODO: create two dataset for train and test\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "first_datapoint = next(iter(dataloader))\n",
    "state, action = first_datapoint\n",
    "\n",
    "print(f\"Number of data_points {len(dataloader)}\")\n",
    "print(f\"Shape of state: {state.shape}\")\n",
    "print(f\"Shape of action: {action.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the Model\n",
    "\n",
    "1. `Encoder`: which will be a simple CNN network.\n",
    "2. `Predictor`: which will be a simple LSTM Cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleEncoder(nn.Module):\n",
    "    def __init__(self, embed_size, input_channel=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channel, 12, padding=1, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(12, 12, padding=1, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(12, 12, padding=1, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "        self.bn3 = nn.BatchNorm2d(12)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d((5, 5), stride=2)\n",
    "        self.pool2 = nn.MaxPool2d((5, 5), stride=5)\n",
    "        # h -> (5, 5, stride=1) -> (3, 3)\n",
    "        # h = 65 -> 8748\n",
    "        self.fc1 = nn.Linear(432, 4096)\n",
    "        self.fc2 = nn.Linear(4096, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # h,w = 65\n",
    "        x = self.conv1(x)        \n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x1 = x\n",
    "\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x2 = x2 + x1\n",
    "        x2 = self.pool1(x2)\n",
    "        # h,w = 31 \n",
    "\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = x3 + x2\n",
    "        x3 = self.pool2(x3)\n",
    "        # h,w = 6\n",
    "\n",
    "        x3 = x3.view(x3.size(0), -1)\n",
    "        # (b,12*6*6)\n",
    "        x3 = self.fc1(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x3 = self.fc2(x3)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VICRegModel(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = VICRegProjectionHead(\n",
    "            input_dim=1024,\n",
    "            hidden_dim=2048,\n",
    "            output_dim=1024,\n",
    "            num_layers=3,\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(x)\n",
    "        return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTMCell(input_size, hidden_size)\n",
    "\n",
    "        self.h = None\n",
    "        self.c = None\n",
    "\n",
    "    def set_hc(self, h, c):\n",
    "        self.h = h\n",
    "        self.c = c \n",
    "    \n",
    "    def reset_hc(self):\n",
    "        self.h = self.h.zero_() \n",
    "        self.c = self.c.zero_()\n",
    "\n",
    "    def forward(self, action):\n",
    "        self.h, self.c = self.lstm_cell(action, (self.h, self.c))\n",
    "        return self.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training \n",
    "We define `train_separate()` function, which does the training step when encoder is trained separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_encoder(dataloader, model, optimizer, criterion, epochs, device, transformation1, \n",
    "                  transformation2, step = 1):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "            state, _ = batch\n",
    "            state = state.to(device)\n",
    "            for i in range(state.size(1)):\n",
    "                img = state[:, i, :, :, :]\n",
    "\n",
    "                x0 = transformation1(img)\n",
    "                x1 = transformation2(img)\n",
    "\n",
    "                _, z0 = model(x0)\n",
    "                _, z1 = model(x1)\n",
    "\n",
    "                loss = criterion(z0, z1)\n",
    "                total_loss += loss.detach()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                avg_loss = total_loss / (len(dataloader)*state.size(1))\n",
    "\n",
    "        # Save model checkpoint\n",
    "        if epoch % step == 0:\n",
    "            save_model(model, epoch)\n",
    "        print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "    print(\"Training completed.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: have to remove the use of `use expander`, it for testing\n",
    "def train_predictor(pred, enc, dataloader, criterion, optimizer, device, \n",
    "                    use_expander=False, epochs=10):\n",
    "    # keeping encoder in eval mode\n",
    "    pred, enc = pred.to(device), enc.to(device)\n",
    "\n",
    "    # freezing the encoder and setting it to evaluation mode\n",
    "    enc.eval()\n",
    "    for param in enc.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(dataloader, desc=\"Processing batch\"):\n",
    "            ## shape of [ s = (B, L+1, C, H, W)]  [a = (B, L, 2)]\n",
    "            s, a = batch\n",
    "            s, a = s.to(device), a.to(device)\n",
    "\n",
    "            ## initial observation\n",
    "            o = s[:, 0, :, :, :]\n",
    "            with torch.no_grad():\n",
    "                x, z = enc(o)\n",
    "                so = z if use_expander else x\n",
    "            \n",
    "            ## initializing predictor h,c\n",
    "            ## check randn instead of zeros\n",
    "            co = torch.zeros(so.shape).to(device)\n",
    "            pred.set_hc(so, co)\n",
    "            \n",
    "            ## forward inference for training.\n",
    "            loss ,L = 0, a.shape[1]\n",
    "            for i in range(L):\n",
    "                sy_hat = pred(a[:, i, :])\n",
    "                si = s[:, i+1, :, :, :]\n",
    "                with torch.no_grad():\n",
    "                    x, z = enc(si)\n",
    "                    sy = z if use_expander else x\n",
    "                loss += criterion(sy_hat, sy)\n",
    "            \n",
    "            ## back-propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ## clearing h,c in lstm \n",
    "            pred.reset_hc()\n",
    "\n",
    "            total_loss += loss\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        save_model(pred, epoch, file_name=\"pred\")\n",
    "        print(f\"epoch: {epoch:>02}, loss: {avg_loss:.9f}\")\n",
    "    print(\"Training completed..\")\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 1024\n",
    "\n",
    "# defining model\n",
    "encoder = SimpleEncoder(hidden_size, 2) \n",
    "encoder = VICRegModel(encoder)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "optimizer = optim.SGD(encoder.parameters(), lr=0.01, momentum=0.9, weight_decay=1.5e-4)\n",
    "\n",
    "# defining transformations\n",
    "mean, std = compute_mean_and_std(dataloader, is_channelsize3=False)\n",
    "transformation1, transformation2 = get_byol_transforms(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:28<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__0.pth\n",
      "epoch: 00, loss: 37.94731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:29<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__1.pth\n",
      "epoch: 01, loss: 37.04359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:32<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__2.pth\n",
      "epoch: 02, loss: 36.08323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__3.pth\n",
      "epoch: 03, loss: 35.82449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__4.pth\n",
      "epoch: 04, loss: 35.56228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__5.pth\n",
      "epoch: 05, loss: 35.44170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__6.pth\n",
      "epoch: 06, loss: 35.37407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__7.pth\n",
      "epoch: 07, loss: 35.31825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__8.pth\n",
      "epoch: 08, loss: 35.15565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 62/62 [00:34<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/encoder__9.pth\n",
      "epoch: 09, loss: 35.18352\n",
      "Training completed.\n",
      "Model saved to checkpoints/encoder__encoder.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = train_encoder(dataloader, encoder, optimizer, VICReg_criterion, 10, \n",
    "              device, transformation1, transformation2)\n",
    "\n",
    "save_model(encoder, \"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4928/2835768945.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  encoder.load_state_dict(torch.load(\"./checkpoints/encoder__9.pth\"))\n"
     ]
    }
   ],
   "source": [
    "input_size = 2\n",
    "hidden_size = 1024\n",
    "\n",
    "# loading encoder\n",
    "encoder.load_state_dict(torch.load(\"./checkpoints/encoder__9.pth\"))\n",
    "\n",
    "# loading the model\n",
    "predictor = Predictor(input_size=input_size, hidden_size=hidden_size)\n",
    "predictor_optimizer = optim.SGD(predictor.parameters(), lr=0.001, momentum=0.9, weight_decay=1.5e-4)\n",
    "predictor_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_0.pth\n",
      "epoch: 00, loss: 6091.095214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_1.pth\n",
      "epoch: 01, loss: 5925.533691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_2.pth\n",
      "epoch: 02, loss: 5924.496582031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_3.pth\n",
      "epoch: 03, loss: 5924.109863281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_4.pth\n",
      "epoch: 04, loss: 5923.988281250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_5.pth\n",
      "epoch: 05, loss: 5923.827636719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_6.pth\n",
      "epoch: 06, loss: 5923.610351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_7.pth\n",
      "epoch: 07, loss: 5923.518554688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_8.pth\n",
      "epoch: 08, loss: 5923.479003906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_9.pth\n",
      "epoch: 09, loss: 5923.376953125\n",
      "Training completed..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predictor(\n",
       "  (lstm_cell): LSTMCell(2, 1024)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictor(predictor, encoder, dataloader, predictor_criterion,\n",
    "                predictor_optimizer, device, use_expander=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_0.pth\n",
      "epoch: 00, loss: 8.385624886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_1.pth\n",
      "epoch: 01, loss: 2.296003103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_2.pth\n",
      "epoch: 02, loss: 2.250522852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_3.pth\n",
      "epoch: 03, loss: 2.204568386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_4.pth\n",
      "epoch: 04, loss: 2.158132315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_5.pth\n",
      "epoch: 05, loss: 2.110890388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_6.pth\n",
      "epoch: 06, loss: 2.062494516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_7.pth\n",
      "epoch: 07, loss: 2.012619734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_8.pth\n",
      "epoch: 08, loss: 1.960875630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batch: 100%|██████████| 62/62 [00:02<00:00, 27.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/pred_9.pth\n",
      "epoch: 09, loss: 1.906860113\n",
      "Training completed..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predictor(\n",
       "  (lstm_cell): LSTMCell(2, 1024)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictor(predictor, encoder, dataloader, predictor_criterion,\n",
    "                predictor_optimizer, device, use_expander=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Inference if the Encoder and Decoder is part of the model.\n",
    "If the encoder is trained together with JEPA, we define the forward inference and training step.  \n",
    "The pending step is the defining the loss function and how to do backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JEPAModel(nn.Module):\n",
    "    def __init__(self, embed_size, input_channel_size):\n",
    "        super().__init__()\n",
    "        self.encoder = VICRegModel(SimpleEncoder(embed_size, input_channel_size))\n",
    "        self.predictor = Predictor(2, 1024)\n",
    "        \n",
    "    def set_predictor(self, o, co, use_expander=False):\n",
    "        x, z = self.encoder.forward(o)\n",
    "        so = z if use_expander else x\n",
    "        self.predictor.set_hc(so, co)\n",
    "        return so\n",
    "    \n",
    "    def reset_predictor(self):\n",
    "        self.predictor.reset_hc()\n",
    "\n",
    "    # sy_hat is state repr from predictor using actions\n",
    "    # sy = (sy_enc, sy_exp), is state repr from encoder using states\n",
    "    def forward(self, action=None, state=None):\n",
    "        sy_hat, sy = None, None\n",
    "        if action is not None:\n",
    "            sy_hat = self.predictor(action)\n",
    "        if state is not None:\n",
    "            sy = self.encoder(state)\n",
    "\n",
    "        return sy_hat, sy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_inference(model, actions, states):\n",
    "    # shape of states = (b, L+1, c, h, w)\n",
    "    # shape of action = (b, L, 2)\n",
    "    B, L, D = state.shape[0], actions.shape[1], model.predictor.hidden_size\n",
    "\n",
    "    o = states[:, 0, :, :, :]\n",
    "    co = torch.zeros((B, D)).to(o.device)\n",
    "    model.set_predictor(o, co, use_expander=False)\n",
    "\n",
    "    result = torch.empty((B, L, D))\n",
    "    for i in range(L):\n",
    "        sy_hat, _ = model(actions[:, i, :], states[:, i+1, :, :, :])\n",
    "        result[:, i, :] = sy_hat\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states shape: torch.Size([16, 17, 2, 65, 65])\n",
      "actions shape: torch.Size([16, 16, 2])\n",
      "torch.Size([16, 16, 1024])\n"
     ]
    }
   ],
   "source": [
    "model = JEPAModel(1024, 2)\n",
    "\n",
    "# first_datapoint = next(iter(dataloader))\n",
    "states, actions = first_datapoint\n",
    "model = model.to(device)\n",
    "states = states.to(device)\n",
    "actions = actions.to(device)\n",
    "\n",
    "print(f\"states shape: {states.shape}\")\n",
    "print(f\"actions shape: {actions.shape}\")\n",
    "\n",
    "result = forward_inference(model, actions, states)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are doing training of encoder and predictor together, then we need to handle all the different losses, defined in the figure\n",
    "\n",
    "![loss diagram](../../assets/loss_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_joint(model, dataloader, criterion_encoder, criterion_pred, optimizer, \n",
    "                device, epochs=10, use_expander=False):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    # clipping the gradient to handle gradient explosions in LSTM\n",
    "    max_val = 5.0\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            param.grad.data = torch.clamp(param.grad.data, -max_val, max_val)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=\"Processing Batch\"):\n",
    "            state, action = batch\n",
    "            state, action = state.to(device), action.to(device)\n",
    "            B, L, D = state.shape[0], action.shape[1], model.predictor.hidden_size\n",
    "\n",
    "            loss, loss1, loss2, loss3 = 0, 0, 0, 0\n",
    "\n",
    "            ## initializing the h,c of predictor \n",
    "            o = states[:, 0, :, :, :]\n",
    "            c0 = torch.zeros((B, D)).to(device)\n",
    "            model.set_predictor(o, c0, use_expander)\n",
    "\n",
    "            # compute loss1\n",
    "            loss1 = get_encoder_loss(model, o, transformation1, transformation2, \n",
    "                                     criterion_encoder)\n",
    "            for i in range(L):\n",
    "                # inference of encoder(next state) and predictor(action) \n",
    "                sy_hat, (sy_enc, sy_exp) = model(action[:, i, :], state[:, i+1, :, :, :])\n",
    "                sy = sy_exp if use_expander else sy_enc\n",
    "\n",
    "                # compute loss2 (distance btw sy and sy_hat)\n",
    "                loss2 += criterion_pred(sy_hat, sy)\n",
    "                # vic_reg loss for encoder (for encoding next state)\n",
    "                loss3 += get_encoder_loss(model, state[:, i, :, :, :], \n",
    "                                          transformation1, transformation2, \n",
    "                                          criterion_encoder) \n",
    "            \n",
    "            # adding all loss and doing back propagation\n",
    "            loss = loss1 + loss2 + loss3\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch: {epoch}, total_loss: {total_loss}, the avg loss = {total_loss/len(dataloader)}\")\n",
    "        save_model(model, epoch, file_name=\"join_model\")\n",
    "\n",
    "    return model        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1.5e-4)\n",
    "criterion_predictor = nn.MSELoss()\n",
    "criterion_encoder = VICReg_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 62/62 [00:36<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, total_loss: 41382.16864013672, the avg loss = 667.454332905431\n",
      "Model saved to checkpoints/join_model_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 62/62 [00:35<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total_loss: 39694.914123535156, the avg loss = 640.2405503795993\n",
      "Model saved to checkpoints/join_model_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 62/62 [00:36<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, total_loss: 38815.533447265625, the avg loss = 626.0569910849295\n",
      "Model saved to checkpoints/join_model_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JEPAModel(\n",
       "  (encoder): VICRegModel(\n",
       "    (backbone): SimpleEncoder(\n",
       "      (conv1): Conv2d(2, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv3): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (pool1): MaxPool2d(kernel_size=(5, 5), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (pool2): MaxPool2d(kernel_size=(5, 5), stride=5, padding=0, dilation=1, ceil_mode=False)\n",
       "      (fc1): Linear(in_features=432, out_features=4096, bias=True)\n",
       "      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    )\n",
       "    (projection_head): VICRegProjectionHead(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "        (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        (4): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "        (6): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): Predictor(\n",
       "    (lstm_cell): LSTMCell(2, 1024)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the joint model\n",
    "train_joint(model, dataloader, criterion_encoder, criterion_predictor, \n",
    "            joint_optimizer, device, 3, use_expander=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
